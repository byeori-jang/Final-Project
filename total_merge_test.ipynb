{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7d1d94-80f6-43af-af6c-ff126322799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ†• ìƒˆë¡œìš´ ë³‘í•©ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "âœ… ì²« íŒŒì¼ ì €ì¥ ì™„ë£Œ: ë³‘í•©/merged_step_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“ íŒŒì¼ ë³‘í•© ì¤‘:   0%|                                                                         | 0/7 [00:00<?, ?file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“„ ë³‘í•© ì¤‘: test_2_ì‹ ìš©ì •ë³´_ëª¨ë¸ë§ìš©.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“ íŒŒì¼ ë³‘í•© ì¤‘:  14%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                       | 1/7 [00:12<01:12, 12.15s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: ë³‘í•©/merged_step_test.csv (ì—´ 104)\n",
      "\n",
      "ğŸ“„ ë³‘í•© ì¤‘: test_3_ë§¤ì¶œì •ë³´_unique_í•™ìŠµìš©.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“ íŒŒì¼ ë³‘í•© ì¤‘:  29%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                              | 2/7 [01:03<02:55, 35.15s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: ë³‘í•©/merged_step_test.csv (ì—´ 501)\n",
      "\n",
      "ğŸ“„ ë³‘í•© ì¤‘: test_4.ì²­êµ¬ì…ê¸ˆì •ë³´_ë³€ë™ì—†ìŒ.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“ íŒŒì¼ ë³‘í•© ì¤‘:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                     | 3/7 [01:45<02:20, 35.19s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: ë³‘í•©/merged_step_test.csv (ì—´ 545)\n",
      "\n",
      "ğŸ“„ ë³‘í•© ì¤‘: test_5.ì”ì•¡ì •ë³´_EDA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 63: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m file = file_paths[i]\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ“„ ë³‘í•© ì¤‘: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m df = optimize_types(df)\n\u001b[32m     56\u001b[39m merged = pd.concat([merged, df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mID\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:574\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:663\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._get_header\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:322\u001b[39m, in \u001b[36mdecode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0x80 in position 63: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# â–¶ Base ê²½ë¡œ\n",
    "base_path = \"ë§ˆì´ë°•ìŠ¤ ë‹¤ìš´ë¡œë“œ\\\\ìµœì¢…EDA_uniqueì œê±° ì „ì²´\\\\test\\\\\"\n",
    "\n",
    "# â–¶ ë³‘í•© ëŒ€ìƒ íŒŒì¼ ëª©ë¡\n",
    "file_names = [\n",
    "    \"test_1_íšŒì›ì •ë³´_ëª¨ë¸ë§ìš©.csv\",\n",
    "    \"test_2_ì‹ ìš©ì •ë³´_ëª¨ë¸ë§ìš©.csv\",\n",
    "    \"test_3_ë§¤ì¶œì •ë³´_unique_í•™ìŠµìš©.csv\",\n",
    "    \"test_4.ì²­êµ¬ì…ê¸ˆì •ë³´_ë³€ë™ì—†ìŒ.csv\",\n",
    "    \"test_5.ì”ì•¡ì •ë³´_EDA.csv\",\n",
    "    \"test_6.ì±„ë„ì •ë³´_unique.csv\",\n",
    "    \"test_7_ë§ˆì¼€íŒ…ì •ë³´_unique.csv\",\n",
    "    \"test_8_ì„±ê³¼ì •ë³´_ë³€ë™ì—†ìŒ_ê²°ì¸¡ì¹˜ì²˜ë¦¬.csv\"\n",
    "]\n",
    "file_paths = [base_path + fname for fname in file_names]\n",
    "\n",
    "# â–¶ ë°ì´í„° íƒ€ì… ìµœì í™” í•¨ìˆ˜\n",
    "def optimize_types(df):\n",
    "    for col in df.select_dtypes(include='number').columns:\n",
    "        if 'float' in str(df[col].dtype):\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif 'int' in str(df[col].dtype):\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    for col in df.select_dtypes(include='object').columns:\n",
    "        if df[col].nunique() / len(df) < 0.5:\n",
    "            df[col] = df[col].astype('category')\n",
    "    return df\n",
    "\n",
    "# â–¶ ì €ì¥ ê²½ë¡œ\n",
    "step_path = \"ë³‘í•©/merged_step_test.csv\"\n",
    "final_path = \"ë³‘í•©/ì „ì²´ ë³‘í•©_test.csv\"\n",
    "\n",
    "# â–¶ ì¬ì‹œì‘ ì—¬ë¶€ íŒë‹¨\n",
    "if os.path.exists(step_path):\n",
    "    print(\"âœ… ì´ì „ ë³‘í•© íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ ì´ì–´ì„œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "    merged = pd.read_csv(step_path)\n",
    "    start_idx = len(merged.columns) - 1  # ID í¬í•¨\n",
    "else:\n",
    "    print(\"ğŸ†• ìƒˆë¡œìš´ ë³‘í•©ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "    df = pd.read_csv(file_paths[0])\n",
    "    df = optimize_types(df)\n",
    "    merged = df.copy()\n",
    "    merged.to_csv(step_path, index=False)\n",
    "    print(f\"âœ… ì²« íŒŒì¼ ì €ì¥ ì™„ë£Œ: {step_path}\")\n",
    "    del df\n",
    "    gc.collect()\n",
    "    start_idx = 1  # ì²« íŒŒì¼ ì´í›„ë¶€í„° ì‹œì‘\n",
    "\n",
    "# â–¶ tqdmìœ¼ë¡œ ë³‘í•© ì§„í–‰\n",
    "for i in tqdm(range(start_idx, len(file_paths)), desc=\"ğŸ“ íŒŒì¼ ë³‘í•© ì¤‘\", unit=\"file\"):\n",
    "    file = file_paths[i]\n",
    "    print(f\"\\nğŸ“„ ë³‘í•© ì¤‘: {file_names[i]}\")\n",
    "    df = pd.read_csv(file)\n",
    "    df = optimize_types(df)\n",
    "\n",
    "    merged = pd.concat([merged, df.drop(columns=['ID'], errors='ignore')], axis=1)\n",
    "    merged.to_csv(step_path, index=False)\n",
    "    print(f\"âœ… ì¤‘ê°„ ì €ì¥ ì™„ë£Œ: {step_path} (ì—´ {merged.shape[1]})\")\n",
    "\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "# â–¶ ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° (ID ë“±)\n",
    "merged = merged.loc[:, ~merged.columns.duplicated()]\n",
    "\n",
    "# â–¶ ìµœì¢… ì €ì¥\n",
    "merged.to_csv(final_path, index=False)\n",
    "print(f\"\\nğŸ‰ ìµœì¢… ë³‘í•© ì™„ë£Œ: {final_path} (í–‰ {merged.shape[0]}, ì—´ {merged.shape[1]})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
